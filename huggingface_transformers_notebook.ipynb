{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4f20dc8e9b63a1",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T07:07:34.204336Z",
     "start_time": "2023-08-27T07:07:03.715248Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support %d tasks as followings:\n",
      "audio : audio-classification\n",
      "image : image-classification\n",
      "image : depth-estimation\n",
      "multimodal : automatic-speech-recognition\n",
      "multimodal : feature-extraction\n",
      "multimodal : visual-question-answering\n",
      "multimodal : document-question-answering\n",
      "multimodal : zero-shot-image-classification\n",
      "multimodal : zero-shot-audio-classification\n",
      "multimodal : image-segmentation\n",
      "multimodal : image-to-text\n",
      "multimodal : object-detection\n",
      "multimodal : zero-shot-object-detection\n",
      "multimodal : mask-generation\n",
      "text : text-classification\n",
      "text : token-classification\n",
      "text : question-answering\n",
      "text : table-question-answering\n",
      "text : fill-mask\n",
      "text : summarization\n",
      "text : translation\n",
      "text : text2text-generation\n",
      "text : text-generation\n",
      "text : zero-shot-classification\n",
      "text : conversational\n",
      "video : video-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/fubin/.cache/huggingface/datasets/madao33___csv/madao33--new-title-chinese-2423910db071caac/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e7d254550544ee7afec557101e4fc8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/5850 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da267cc439584596b9e6f69883f62ed1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/1679 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0fe8f90abd504ed096114361f321db1a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading builder script:   0%|          | 0.00/4.59k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2fdd162d384b422eb92ca9a0bfffeeba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading metadata:   0%|          | 0.00/2.16k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "98a82369c10c406b851df0a683cdf816"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading readme:   0%|          | 0.00/3.48k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62a7926fbd864d2db7fea59df1a37409"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset peoples_daily_ner/peoples_daily_ner to /Users/fubin/Downloads/复习/NLP/src/./data/peoples_daily_ner/peoples_daily_ner/peoples_daily_ner/1.0.0/594461a1b34f61af9346123a420b9ea40f15c0e835562053bf025cef188477f5...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddff537bac8840faa0ee3c6d79ad5aa1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/1.84M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82766c766c494318adf8f46889f7900b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/207k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af1682c4429c462a82c8774471401ab2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/394k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d1df62843564fb7b1cb4b3aee612e61"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d1ce4c32f8e4b97b48c0491c4259d7f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split:   0%|          | 0/20865 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f5a0682e2ee44ae9114ca7b1acd9143"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating validation split:   0%|          | 0/2319 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e86a674a4b844daafa20c59b6780e36"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split:   0%|          | 0/4637 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ede1879a27044a57b0ebacad362a0ea5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset peoples_daily_ner downloaded and prepared to /Users/fubin/Downloads/复习/NLP/src/./data/peoples_daily_ner/peoples_daily_ner/peoples_daily_ner/1.0.0/594461a1b34f61af9346123a420b9ea40f15c0e835562053bf025cef188477f5. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dcb891e338c545bc8e3997c11752d001"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# huggingface transformers 教程来完成各项NLP任务\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 1.transformers支持的任务：\n",
    "from transformers import pipelines\n",
    "type_task = sorted([(v['type'], k) for k,v in pipelines.SUPPORTED_TASKS.items()], key=lambda x:x[0])\n",
    "print('support %d tasks as followings:')\n",
    "for t in type_task:\n",
    "    print(t[0],':', t[1])\n",
    "    \n",
    "# 2.huggingface支持的模型： https://huggingface.co/models\n",
    "# 加载tokenizer和model模型到本地: 这里采用roberta-base-finetuned-dianping-chinese模型\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "model_url = \"uer/roberta-base-finetuned-dianping-chinese\"\n",
    "model_dirpath = './models/roberta-base-finetuned-dianping-chinese'\n",
    "model = AutoModel.from_pretrained(model_url)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_url)\n",
    "model.save_pretrained(model_dirpath)\n",
    "tokenizer.save_pretrained(model_dirpath)\n",
    "model = AutoModel.from_pretrained(model_dirpath)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dirpath)\n",
    "\n",
    "# 数据集下载、保存、加载\n",
    "from datasets import load_dataset, load_from_disk\n",
    "data_fpath = \"./data/madao33-new-title-chinese\"\n",
    "dataset = load_dataset(\"madao33/new-title-chinese\") # 从互联网下载\n",
    "dataset.save_to_disk(data_fpath) # 保存\n",
    "dataset = load_from_disk(data_fpath) # 加载\n",
    "ner_datasets = load_dataset(\"peoples_daily_ner\")\n",
    "dataset.save_to_disk('./data/peoples_daily_ner') # 保存\n",
    "datasets = load_dataset(\"cmrc2018\")\n",
    "dataset.save_to_disk('./data/cmrc2018') # 保存\n",
    "from datasets import DatasetDict\n",
    "dataset = DatasetDict.load_from_disk(\"./c3/\")\n",
    "dataset.save_to_disk('./data/c3') # 保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0af517ed8557bb3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T06:38:03.302153Z",
     "start_time": "2023-08-27T06:38:02.113860Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词典： 21128 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./models/roberta-base-finetuned-dianping-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "直接编码： {'input_ids': tensor([[ 101, 2769, 6230, 2533,  679, 1922, 6121, 8013,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "模型输出： SequenceClassifierOutput(loss=None, logits=tensor([[-0.1940,  0.0912]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
      "句子分词： ['今', '天', '食', '堂', '的', '饭', '菜', '好', '难', '吃', '啊', '！']\n",
      "分词编码： [791, 1921, 7608, 1828, 4638, 7649, 5831, 1962, 7410, 1391, 1557, 8013]\n",
      "分词解码： ['今', '天', '食', '堂', '的', '饭', '菜', '好', '难', '吃', '啊', '！']\n",
      "带特殊字符的编码过程： [101, 791, 1921, 7608, 1828, 4638, 7649, 5831, 1962, 7410, 1391, 1557, 8013, 102, 0, 0, 0, 0, 0, 0]\n",
      "带特殊字符的解码过程： [CLS] 今 天 食 堂 的 饭 菜 好 难 吃 啊 ！ [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "# 基础类：\n",
    "# 分词+编码\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model_dirpath = './models/roberta-base-finetuned-dianping-chinese'\n",
    "\n",
    "# 第一次线上下载：\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dirpath, use_fast=True) # true则采用快速分词，否则采用慢速分词，默认是快速分词\n",
    "print('词典：', tokenizer.vocab_size, '...') #  tokenizer.vocab, \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dirpath)\n",
    "# 保存后，再读取\n",
    "# tokenizer.save_pretrained(\"./modules/roberta_tokenizer\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"./modules/roberta_tokenizer/\")\n",
    "# model.save_pretrained(\"./modules/roberta_seqclassification\")\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"./modules/roberta_seqclassification/\")\n",
    "\n",
    "# 分词：model.config.id2label\n",
    "inputs = tokenizer(\"我觉得不太行！\", return_tensors=\"pt\") # 返回pytorch tensor数据类型\n",
    "print('直接编码：', inputs)\n",
    "# 分词编码后喂给模型\n",
    "res = model(**inputs)\n",
    "print('模型输出：', res)\n",
    "\n",
    "# 分词编码过程详细分析：\n",
    "sentence = '今天食堂的饭菜好难吃啊！'\n",
    "# 1.句子分词\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "print('句子分词：', tokens)\n",
    "# 2.将词序列转换为id序列\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "print('分词编码：', ids)\n",
    "# 3.编码转词\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "print('分词解码：', tokens)\n",
    "\n",
    "# 分词编码简化编码-解码过程：带特殊字符\n",
    "ids = tokenizer.encode(sentence, add_special_tokens=True, padding=\"max_length\", max_length=20)\n",
    "print('带特殊字符的编码过程：', ids)\n",
    "tokens = tokenizer.decode(ids, skip_special_tokens=False, max_length=20, truncation=True)\n",
    "print('带特殊字符的解码过程：', tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1114f2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-27T06:10:59.848992Z",
     "start_time": "2023-08-27T06:10:55.963300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/fubin/.cache/huggingface/datasets/madao33___csv/madao33--new-title-chinese-2423910db071caac/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbc10fcf69e94e5ca18052e9822aaf91"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/fubin/.cache/huggingface/datasets/madao33___csv/madao33--new-title-chinese-2423910db071caac/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-d8830fc13ea72998.arrow\n",
      "Loading cached processed dataset at /Users/fubin/.cache/huggingface/datasets/madao33___csv/madao33--new-title-chinese-2423910db071caac/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-8f471df9b551fcc5.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/5850 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8434e3e4dfce48ca9dbf11aff865cd3c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Saving the dataset (0/1 shards):   0%|          | 0/1679 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c78b39cf3bb64b9a9f1c63d8e64ee9c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 基础类： Dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model_dirpath = './models/roberta-base-finetuned-dianping-chinese'\n",
    "data_fpath = \"./data/madao33-new-title-chinese\"\n",
    "\n",
    "# 加载数据\n",
    "dataset = load_dataset(data_fpath)\n",
    "# boolq_dataset = load_dataset(\"super_glue\", \"boolq\") # 加载某项任务数据\n",
    "# dataset = load_dataset(\"madao33/new-title-chinese\", split=\"train\")\n",
    "# dataset = load_dataset(\"madao33/new-title-chinese\", split=\"train[10:100]\")\n",
    "# dataset = load_dataset(\"madao33/new-title-chinese\", split=\"train[:50%]\")\n",
    "# dataset = load_dataset(\"madao33/new-title-chinese\", split=[\"train[:50%]\", \"train[50%:]\"])\n",
    "# 划分数据\n",
    "# dataset.train_test_split(test_size=0.1)\n",
    "# dataset.train_test_split(test_size=0.1, stratify_by_column=\"label\")     # 分类数据集可以按照比例划分\n",
    "# 过滤\n",
    "# filter_dataset = dataset[\"train\"].filter(lambda example: \"中国\" in example[\"title\"])\n",
    "def add_prefix(example):\n",
    "    example[\"title\"] = 'Prefix: ' + example[\"title\"]\n",
    "    return example\n",
    "prefix_dataset = dataset.map(add_prefix)\n",
    "# def process_function(examples):\n",
    "#     tokenized_examples = tokenizer(examples[\"review\"], max_length=128, truncation=True)\n",
    "#     tokenized_examples[\"labels\"] = examples[\"label\"]\n",
    "#     return tokenized_examples\n",
    "# tokenized_dataset = dataset.map(process_function, batched=True, remove_columns=dataset.column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1698afc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-27T06:53:10.497244Z",
     "start_time": "2023-08-27T06:52:55.438707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['precision', 'code_eval', 'roc_auc', 'cuad', 'xnli', 'rouge', 'pearsonr', 'mse', 'super_glue', 'comet', 'cer', 'sacrebleu', 'mahalanobis', 'wer', 'competition_math', 'f1', 'recall', 'coval', 'mauve', 'xtreme_s', 'bleurt', 'ter', 'accuracy', 'exact_match', 'indic_glue', 'spearmanr', 'mae', 'squad', 'chrf', 'glue', 'perplexity', 'mean_iou', 'squad_v2', 'meteor', 'bleu', 'wiki_split', 'sari', 'frugalscore', 'google_bleu', 'bertscore', 'matthews_correlation', 'seqeval', 'trec_eval', 'rl_reliability', 'poseval', 'brier_score', 'mase', 'mape', 'smape', 'nist_mt', 'character', 'charcut_mt', 'r_squared', 'mcnemar', 'exact_match', 'wilcoxon', 'word_length', 'word_count', 'text_duplicates', 'perplexity', 'label_distribution', 'toxicity', 'regard', 'honest']\n",
      "单个累积： {'accuracy': 0.5}\n",
      "batch累积： {'accuracy': 0.5}\n",
      "{'accuracy': 0.6666666666666666, 'f1': 0.6666666666666666, 'recall': 0.5, 'precision': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 5 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 基础类：评价标准\n",
    "import evaluate\n",
    "from evaluate.visualization import radar_plot\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 评价标准总表\n",
    "print([d['name'] for d in evaluate.list_evaluation_modules(include_community=False, with_details=True)])\n",
    "\n",
    "# 评价：\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "for ref, pred in zip([0,1,0,1], [1,0,0,1]):\n",
    "    accuracy.add(references=ref, predictions=pred)\n",
    "print('单个累积：', accuracy.compute())\n",
    "for refs, preds in zip([[0,1],[0,1]], [[1,0],[0,1]]):\n",
    "    accuracy.add_batch(references=refs, predictions=preds)\n",
    "print('batch累积：', accuracy.compute())\n",
    "# 多个评价标准\n",
    "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"recall\", \"precision\"])\n",
    "result = clf_metrics.compute(predictions=[0, 1, 0], references=[0, 1, 1])\n",
    "print(result)\n",
    "# 画雷达图\n",
    "data = [{\"accuracy\": 0.99, \"precision\": 0.8, \"f1\": 0.95, \"latency_in_seconds\": 33.6},\n",
    "   {\"accuracy\": 0.98, \"precision\": 0.87, \"f1\": 0.91, \"latency_in_seconds\": 11.2},\n",
    "   {\"accuracy\": 0.98, \"precision\": 0.78, \"f1\": 0.88, \"latency_in_seconds\": 87.6}, \n",
    "   {\"accuracy\": 0.88, \"precision\": 0.78, \"f1\": 0.81, \"latency_in_seconds\": 101.6} ]\n",
    "plot = radar_plot(data=data, model_names=[\"Model 1\", \"Model 2\", \"Model 3\", \"Model 4\"])\n",
    "plot.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f0a4f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-27T06:26:41.799843Z",
     "start_time": "2023-08-27T06:24:59.914984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576 64\n",
      "ep: 1, local_step: 1, loss: 0.7810053825378418\n",
      "ep: 1, local_step: 2, loss: 0.7198745012283325\n",
      "ep: 1, local_step: 3, loss: 0.6048681735992432\n",
      "ep: 1, local_step: 4, loss: 0.6180012226104736\n",
      "ep: 1, local_step: 5, loss: 0.27919960021972656\n",
      "ep: 1, local_step: 6, loss: 0.2787778377532959\n",
      "ep: 1, local_step: 7, loss: 0.27635517716407776\n",
      "ep: 1, local_step: 8, loss: 0.12575605511665344\n",
      "ep: 1, local_step: 9, loss: 0.16460415720939636\n",
      "ep: 1, local_step: 10, loss: 0.1353130340576172\n",
      "ep: 1, local_step: 11, loss: 0.13470979034900665\n",
      "ep: 1, local_step: 12, loss: 0.09783849120140076\n",
      "ep: 1, local_step: 13, loss: 0.05854212865233421\n",
      "ep: 1, local_step: 14, loss: 0.09134873747825623\n",
      "ep: 1, local_step: 15, loss: 0.05543891340494156\n",
      "ep: 1, local_step: 16, loss: 0.020365536212921143\n",
      "ep: 1, local_step: 17, loss: 0.037340205162763596\n",
      "ep: 1, local_step: 18, loss: 0.02863709256052971\n",
      "ep: 0, acc: 1.0\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": "[{'label': '好评！', 'score': 0.9916306138038635}]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提高类：封装Dataset和DataLoader\n",
    "# 自定义数据集\n",
    "\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model_dirpath = './models/roberta-base-finetuned-dianping-chinese'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "data_fpath = \"./data/ChnSentiCorp/ChnSentiCorp_htl_all.csv\"\n",
    "\n",
    "# 自定义数据集并预处理和加载\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame) -> None:\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.data = self.data.dropna()\n",
    "    def __getitem__(self, index):\n",
    "        return self.data.iloc[index][\"review\"], self.data.iloc[index][\"label\"]\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "dataset = MyDataset(pd.read_csv(data_fpath).head(64*10))\n",
    "trainset, validset = random_split(dataset, lengths=[0.9, 0.1])\n",
    "print(len(trainset), len(validset))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dirpath)\n",
    "def collate_func(batch):\n",
    "    texts, labels = [], []\n",
    "    for item in batch:\n",
    "        texts.append(item[0])\n",
    "        labels.append(item[1])\n",
    "    inputs = tokenizer(texts, max_length=128, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    inputs[\"labels\"] = torch.tensor(labels)\n",
    "    return inputs\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True, collate_fn=collate_func)\n",
    "validloader = DataLoader(validset, batch_size=64, shuffle=False, collate_fn=collate_func)\n",
    "\n",
    "# 模型、训练\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dirpath).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=2e-5)\n",
    "def evaluate():\n",
    "    model.eval()\n",
    "    acc_num = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch in validloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            output = model(**batch)\n",
    "            pred = torch.argmax(output.logits, dim=-1)\n",
    "            acc_num += (pred.long() == batch[\"labels\"].long()).float().sum()\n",
    "    return acc_num / len(validset)\n",
    "\n",
    "def train(epoch=1, log_step=100):\n",
    "    for ep in range(epoch):\n",
    "        model.train()\n",
    "        for i, batch in enumerate(trainloader):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            output = model(**batch)\n",
    "            output.loss.backward()\n",
    "            optimizer.step()\n",
    "            print(f\"ep: {ep+1}, local_step: {i+1}, loss: {output.loss.item()}\")\n",
    "        acc = evaluate()\n",
    "        print(f\"ep: {ep}, acc: {acc}\")\n",
    "train()\n",
    "# 预测\n",
    "sen = \"我觉得这家酒店不错，饭很好吃！\"\n",
    "model.eval()\n",
    "model.config.id2label = {0: \"差评！\", 1: \"好评！\"}\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device)\n",
    "pipe(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/fubin/.cache/huggingface/datasets/csv/default-797321f2014d2b18/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "Loading cached processed dataset at /Users/fubin/.cache/huggingface/datasets/csv/default-797321f2014d2b18/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-e5f6a43ee00b7131.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/576 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e17d2c54cfc4c04a878cd75751c6daa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/64 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2da0e4ce609a4b9aa65b986e66dc641a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./models/roberta-base-finetuned-dianping-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/9 : < :, Epoch 0.11/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[{'label': '好评！', 'score': 0.7101271748542786}]\n"
     ]
    }
   ],
   "source": [
    "# 封装训练器：Trainer 和 TrainingArguments\n",
    "# AutoModelForSequenceClassification\n",
    "\n",
    "import torch, evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, Trainer, TrainingArguments, pipeline\n",
    "from datasets import load_dataset\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model_dirpath = './models/roberta-base-finetuned-dianping-chinese'\n",
    "data_fpath = \"./data/ChnSentiCorp/ChnSentiCorp_htl_all.csv\"\n",
    "checkpoints_dirpath = './checkpoints'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "\n",
    "# 加载数据\n",
    "dataset = load_dataset(\"csv\", data_files=data_fpath, split=\"train[:640]\")\n",
    "dataset = dataset.filter(lambda x: x[\"review\"] is not None)\n",
    "datasets = dataset.train_test_split(test_size=0.1)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/rbt3\")\n",
    "def process_function(examples):\n",
    "    tokenized_examples = tokenizer(examples[\"review\"], max_length=128, truncation=True)\n",
    "    tokenized_examples[\"labels\"] = examples[\"label\"]\n",
    "    return tokenized_examples\n",
    "tokenized_datasets = datasets.map(process_function, batched=True, remove_columns=datasets[\"train\"].column_names)\n",
    "# 评估标准\n",
    "acc_metric = evaluate.load(\"accuracy\")\n",
    "f1_metirc = evaluate.load(\"f1\")\n",
    "def eval_metric(eval_predict):\n",
    "    predictions, labels = eval_predict\n",
    "    predictions = predictions.argmax(axis=-1)\n",
    "    acc = acc_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metirc.compute(predictions=predictions, references=labels)\n",
    "    acc.update(f1)\n",
    "    return acc\n",
    "# 模型训练\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dirpath)\n",
    "train_args = TrainingArguments(output_dir=checkpoints_dirpath,      # 输出文件夹\n",
    "                               per_device_train_batch_size=64,  # 训练时的batch_size\n",
    "                               per_device_eval_batch_size=128,  # 验证时的batch_size\n",
    "                               logging_steps=10,                # log 打印的频率\n",
    "                               evaluation_strategy=\"epoch\",     # 评估策略\n",
    "                               save_strategy=\"epoch\",           # 保存策略\n",
    "                               save_total_limit=3,              # 最大保存数\n",
    "                               learning_rate=2e-5,              # 学习率\n",
    "                               weight_decay=0.01,               # weight_decay\n",
    "                               metric_for_best_model=\"f1\",      # 设定评估指标\n",
    "                               num_train_epochs=1,\n",
    "                               load_best_model_at_end=True)     # 训练完成后加载最优模型\n",
    "trainer = Trainer(model=model,  args=train_args, train_dataset=tokenized_datasets[\"train\"], eval_dataset=tokenized_datasets[\"test\"], data_collator=DataCollatorWithPadding(tokenizer=tokenizer), compute_metrics=eval_metric)\n",
    "trainer.train()\n",
    "# 模型预测\n",
    "model.eval()\n",
    "sen = \"我觉得这家酒店不错，饭很好吃！\"\n",
    "model.config.id2label = {0: \"差评！\", 1: \"好评！\"}\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device)\n",
    "print(pipe(sen))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T07:06:31.794108Z",
     "start_time": "2023-08-27T07:04:23.017768Z"
    }
   },
   "id": "5af1eb7fee67b5c0"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at ./models/roberta-base-finetuned-dianping-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Loading cached processed dataset at /Users/fubin/Downloads/复习/NLP/src/data/peoples_daily_ner/train/cache-75b45d5bccc8ba28.arrow\n",
      "Loading cached processed dataset at /Users/fubin/Downloads/复习/NLP/src/data/peoples_daily_ner/validation/cache-22edf8801460533b.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/4637 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d2c7d7167e88447680510f9aa978a12e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[{'entity_group': 'LABEL_0', 'score': 0.1744266, 'word': '小 明', 'start': 0, 'end': 2}, {'entity_group': 'LABEL_6', 'score': 0.1764205, 'word': '在', 'start': 2, 'end': 3}, {'entity_group': 'LABEL_0', 'score': 0.20054242, 'word': '北 京 上 班', 'start': 3, 'end': 7}]\n"
     ]
    }
   ],
   "source": [
    "# 任务类：\n",
    "# 命名实体识别, AutoModelForTokenClassification\n",
    "\n",
    "import evaluate, torch, seqeval\n",
    "import numpy as np\n",
    "from datasets import DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model_dirpath = './models/roberta-base-finetuned-dianping-chinese'\n",
    "data_fpath = './data/peoples_daily_ner'\n",
    "checkpoints_dirpath = './checkpoints'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "\n",
    "ner_datasets = DatasetDict.load_from_disk(data_fpath)\n",
    "label_list = ner_datasets[\"train\"].features[\"ner_tags\"].feature.names\n",
    "print(label_list)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dirpath)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_dirpath, num_labels=len(label_list)) # 已封装\n",
    "seqeval = evaluate.load(\"./scripts/seqeval_metric.py\")\n",
    "\n",
    "# 借助word_ids 实现标签映射\n",
    "def process_function(examples):\n",
    "    tokenized_exmaples = tokenizer(examples[\"tokens\"], max_length=128, truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_exmaples.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        for word_id in word_ids:\n",
    "            if word_id is None:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_id])\n",
    "        labels.append(label_ids)\n",
    "    tokenized_exmaples[\"labels\"] = labels\n",
    "    return tokenized_exmaples\n",
    "tokenized_datasets = ner_datasets.map(process_function, batched=True)\n",
    "\n",
    "# 评估标准\n",
    "def eval_metric(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    # 将id转换为原始的字符串类型的标签\n",
    "    true_predictions = [[label_list[p] for p, l in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "    true_labels = [[label_list[l] for p, l in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n",
    "    result = seqeval.compute(predictions=true_predictions, references=true_labels, mode=\"strict\", scheme=\"IOB2\")\n",
    "    return {\"f1\": result[\"overall_f1\"]}\n",
    "\n",
    "# 训练和评估\n",
    "# args = TrainingArguments(output_dir=\"./models/models_for_ner\", per_device_train_batch_size=64, per_device_eval_batch_size=128, evaluation_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\", metric_for_best_model=\"f1\", load_best_model_at_end=True, logging_steps=50, num_train_epochs=1)\n",
    "# trainer = Trainer(model=model, args=args, train_dataset=tokenized_datasets[\"train\"], eval_dataset=tokenized_datasets[\"validation\"],\n",
    "#     compute_metrics=eval_metric, data_collator=DataCollatorForTokenClassification(tokenizer=tokenizer))\n",
    "# trainer.train()\n",
    "# print(trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"]))\n",
    "# 封装成pipeline\n",
    "from transformers import pipeline\n",
    "ner_pipe = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, device=device, aggregation_strategy=\"simple\")\n",
    "# 测试\n",
    "print(ner_pipe(\"小明在北京上班\"))\n",
    "# 效果不是很好，一方面这个模型不适合序列标注，另一方面没有进行微调"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T07:54:23.678156Z",
     "start_time": "2023-08-27T07:54:13.411812Z"
    }
   },
   "id": "6a1da1e9398d2829"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T07:59:00.001576Z",
     "start_time": "2023-08-27T07:58:49.552328Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./models/roberta-base-finetuned-dianping-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very good! [{'label': 'POSITIVE', 'score': 0.9998525381088257}] [{'label': 'negative (stars 1, 2 and 3)', 'score': 0.5701478123664856}]\n",
      "我觉得不太行！ [{'label': 'NEGATIVE', 'score': 0.5539907813072205}] [{'label': 'positive (stars 4 and 5)', 'score': 0.5074054598808289}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./models/roberta-base-finetuned-dianping-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我觉得不太行！ [{'label': 'positive (stars 4 and 5)', 'score': 0.568372368812561}] very good! [{'label': 'negative (stars 1, 2 and 3)', 'score': 0.6013391613960266}]\n"
     ]
    }
   ],
   "source": [
    "# 任务类\n",
    "# 文本分类：情感分类pipeline简单实现, AutoModelForSequenceClassification\n",
    "\n",
    "# 设置推理设备\n",
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model_dirpath = './models/roberta-base-finetuned-dianping-chinese'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "\n",
    "# 1.加载线上模型:第一次会下载\n",
    "pipe1 = pipeline(\"text-classification\", device=device) # device=0表示cuda:0\n",
    "pipe2 = pipeline(\"text-classification\", model=model_dirpath, device=device) # device=0表示cuda:0\n",
    "print(\"very good!\", pipe1(\"very good!\"), pipe2(\"very good!\"))\n",
    "print(\"我觉得不太行！\", pipe1(\"我觉得不太行！\"), pipe2(\"我觉得不太行！\"))\n",
    "\n",
    "# 2.加载本地模型：必须同时指定model和tokenizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dirpath)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dirpath)\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device) # device=0表示cuda:0\n",
    "print(\"我觉得不太行！\", pipe(\"我觉得不太行！\"), \"very good!\", pipe(\"very good!\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9049c4a982c8cd3d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-27T07:59:55.006712Z",
     "start_time": "2023-08-27T07:59:53.532359Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ./models/roberta-base-finetuned-dianping-chinese and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中国的首都是哪里？ {'score': 0.013369468040764332, 'start': 1, 'end': 3, 'answer': '国的'}\n"
     ]
    }
   ],
   "source": [
    "# 任务类：\n",
    "# 问答系统：pipeline简单实现\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "model_dirpath = './models/roberta-base-finetuned-dianping-chinese'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "\n",
    "qa_pipe = pipeline(\"question-answering\", model=model_dirpath, device=device)\n",
    "print(\"中国的首都是哪里？\", qa_pipe(question=\"中国的首都是哪里？\", context=\"中国的首都是北京\", max_answer_len=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39bb26a99d11c693",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T13:07:51.168262Z",
     "start_time": "2023-08-28T13:07:30.199073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/10142 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b1b9ac917384581b18785235b3b8224"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/3219 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a03c115c46b34e5ca1ff91f5708becc4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1002 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9f52689b61044e63a6199d09a4454575"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at ./models/roberta-base-finetuned-dianping-chinese and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'score': 0.0139765664935112, 'start': 4, 'end': 7, 'answer': '京上班'}"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 任务类：\n",
    "# 问答系统：截断策略简单实现, AutoModelForQuestionAnswering\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering, TrainingArguments, Trainer, DefaultDataCollator\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "model_dirpath = './models/roberta-base-finetuned-dianping-chinese'\n",
    "datasets = DatasetDict.load_from_disk(\"./data/cmrc2018\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dirpath)\n",
    "sample_dataset = datasets[\"train\"].select(range(10))\n",
    "tokenized_examples = tokenizer(text=sample_dataset[\"question\"], text_pair=sample_dataset[\"context\"], return_offsets_mapping=True, max_length=512, truncation=\"only_second\", padding=\"max_length\")\n",
    "def process_func(examples):\n",
    "    tokenized_examples = tokenizer(text=examples[\"question\"], text_pair=examples[\"context\"], return_offsets_mapping=True, max_length=384, truncation=\"only_second\", padding=\"max_length\")\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "    for idx, offset in enumerate(offset_mapping):\n",
    "        answer = examples[\"answers\"][idx]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = start_char + len(answer[\"text\"][0])\n",
    "        # 定位答案在token中的起始位置和结束位置\n",
    "        # 一种策略，我们要拿到context的起始和结束，然后从左右两侧向答案逼近\n",
    "        context_start = tokenized_examples.sequence_ids(idx).index(1)\n",
    "        context_end = tokenized_examples.sequence_ids(idx).index(None, context_start) - 1\n",
    "        # 判断答案是否在context中\n",
    "        if offset[context_end][1] < start_char or offset[context_start][0] > end_char:\n",
    "            start_token_pos = 0\n",
    "            end_token_pos = 0\n",
    "        else:\n",
    "            token_id = context_start\n",
    "            while token_id <= context_end and offset[token_id][0] < start_char:\n",
    "                token_id += 1\n",
    "            start_token_pos = token_id\n",
    "            token_id = context_end\n",
    "            while token_id >= context_start and offset[token_id][1] > end_char:\n",
    "                token_id -=1\n",
    "            end_token_pos = token_id\n",
    "        start_positions.append(start_token_pos)\n",
    "        end_positions.append(end_token_pos)\n",
    "    tokenized_examples[\"start_positions\"] = start_positions\n",
    "    tokenized_examples[\"end_positions\"] = end_positions\n",
    "    return tokenized_examples\n",
    "tokenied_datasets = datasets.map(process_func, batched=True, remove_columns=datasets[\"train\"].column_names)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_dirpath)\n",
    "args = TrainingArguments(output_dir=\"./models/models_for_qa\", per_device_train_batch_size=32, per_device_eval_batch_size=32,\n",
    "    evaluation_strategy=\"epoch\", save_strategy=\"epoch\", logging_steps=50, num_train_epochs=3)\n",
    "trainer = Trainer(model=model, args=args, train_dataset=tokenied_datasets[\"train\"], eval_dataset=tokenied_datasets[\"validation\"], data_collator=DefaultDataCollator())\n",
    "# trainer.train()\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device=device)\n",
    "pipe(question=\"小明在哪里上班？\", context=\"小明在北京上班。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/1625 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83f337d8526d42568f6253e15a5b1e65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "'' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [16]\u001B[0m, in \u001B[0;36m<cell line: 36>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     34\u001B[0m     tokenized_examples[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m labels\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tokenized_examples\n\u001B[0;32m---> 36\u001B[0m tokenized_c3 \u001B[38;5;241m=\u001B[39m \u001B[43mc3\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_function\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     37\u001B[0m model \u001B[38;5;241m=\u001B[39m AutoModelForMultipleChoice\u001B[38;5;241m.\u001B[39mfrom_pretrained(model_dirpath)\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/dataset_dict.py:852\u001B[0m, in \u001B[0;36mDatasetDict.map\u001B[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001B[0m\n\u001B[1;32m    849\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cache_file_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    850\u001B[0m     cache_file_names \u001B[38;5;241m=\u001B[39m {k: \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m}\n\u001B[1;32m    851\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DatasetDict(\n\u001B[0;32m--> 852\u001B[0m     {\n\u001B[1;32m    853\u001B[0m         k: dataset\u001B[38;5;241m.\u001B[39mmap(\n\u001B[1;32m    854\u001B[0m             function\u001B[38;5;241m=\u001B[39mfunction,\n\u001B[1;32m    855\u001B[0m             with_indices\u001B[38;5;241m=\u001B[39mwith_indices,\n\u001B[1;32m    856\u001B[0m             with_rank\u001B[38;5;241m=\u001B[39mwith_rank,\n\u001B[1;32m    857\u001B[0m             input_columns\u001B[38;5;241m=\u001B[39minput_columns,\n\u001B[1;32m    858\u001B[0m             batched\u001B[38;5;241m=\u001B[39mbatched,\n\u001B[1;32m    859\u001B[0m             batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m    860\u001B[0m             drop_last_batch\u001B[38;5;241m=\u001B[39mdrop_last_batch,\n\u001B[1;32m    861\u001B[0m             remove_columns\u001B[38;5;241m=\u001B[39mremove_columns,\n\u001B[1;32m    862\u001B[0m             keep_in_memory\u001B[38;5;241m=\u001B[39mkeep_in_memory,\n\u001B[1;32m    863\u001B[0m             load_from_cache_file\u001B[38;5;241m=\u001B[39mload_from_cache_file,\n\u001B[1;32m    864\u001B[0m             cache_file_name\u001B[38;5;241m=\u001B[39mcache_file_names[k],\n\u001B[1;32m    865\u001B[0m             writer_batch_size\u001B[38;5;241m=\u001B[39mwriter_batch_size,\n\u001B[1;32m    866\u001B[0m             features\u001B[38;5;241m=\u001B[39mfeatures,\n\u001B[1;32m    867\u001B[0m             disable_nullable\u001B[38;5;241m=\u001B[39mdisable_nullable,\n\u001B[1;32m    868\u001B[0m             fn_kwargs\u001B[38;5;241m=\u001B[39mfn_kwargs,\n\u001B[1;32m    869\u001B[0m             num_proc\u001B[38;5;241m=\u001B[39mnum_proc,\n\u001B[1;32m    870\u001B[0m             desc\u001B[38;5;241m=\u001B[39mdesc,\n\u001B[1;32m    871\u001B[0m         )\n\u001B[1;32m    872\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, dataset \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m    873\u001B[0m     }\n\u001B[1;32m    874\u001B[0m )\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/dataset_dict.py:853\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    849\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cache_file_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    850\u001B[0m     cache_file_names \u001B[38;5;241m=\u001B[39m {k: \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m}\n\u001B[1;32m    851\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DatasetDict(\n\u001B[1;32m    852\u001B[0m     {\n\u001B[0;32m--> 853\u001B[0m         k: \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    854\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwith_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    856\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwith_rank\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwith_rank\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    857\u001B[0m \u001B[43m            \u001B[49m\u001B[43minput_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    858\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatched\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatched\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    859\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    860\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdrop_last_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdrop_last_batch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    861\u001B[0m \u001B[43m            \u001B[49m\u001B[43mremove_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mremove_columns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    862\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkeep_in_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_memory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    863\u001B[0m \u001B[43m            \u001B[49m\u001B[43mload_from_cache_file\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mload_from_cache_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    864\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcache_file_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_file_names\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    865\u001B[0m \u001B[43m            \u001B[49m\u001B[43mwriter_batch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mwriter_batch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    866\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeatures\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    867\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdisable_nullable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable_nullable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m            \u001B[49m\u001B[43mfn_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_proc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_proc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdesc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    872\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, dataset \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems()\n\u001B[1;32m    873\u001B[0m     }\n\u001B[1;32m    874\u001B[0m )\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py:563\u001B[0m, in \u001B[0;36mtransmit_tasks.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    561\u001B[0m     \u001B[38;5;28mself\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    562\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[0;32m--> 563\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    564\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[1;32m    565\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m dataset \u001B[38;5;129;01min\u001B[39;00m datasets:\n\u001B[1;32m    566\u001B[0m     \u001B[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py:528\u001B[0m, in \u001B[0;36mtransmit_format.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    521\u001B[0m self_format \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    522\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_type,\n\u001B[1;32m    523\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mformat_kwargs\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_kwargs,\n\u001B[1;32m    524\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_columns,\n\u001B[1;32m    525\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_all_columns\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_all_columns,\n\u001B[1;32m    526\u001B[0m }\n\u001B[1;32m    527\u001B[0m \u001B[38;5;66;03m# apply actual function\u001B[39;00m\n\u001B[0;32m--> 528\u001B[0m out: Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDatasetDict\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    529\u001B[0m datasets: List[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDataset\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(out\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(out, \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m [out]\n\u001B[1;32m    530\u001B[0m \u001B[38;5;66;03m# re-apply format to the output\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py:2953\u001B[0m, in \u001B[0;36mDataset.map\u001B[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001B[0m\n\u001B[1;32m   2945\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m transformed_dataset \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2946\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m logging\u001B[38;5;241m.\u001B[39mtqdm(\n\u001B[1;32m   2947\u001B[0m         disable\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m logging\u001B[38;5;241m.\u001B[39mis_progress_bar_enabled(),\n\u001B[1;32m   2948\u001B[0m         unit\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m examples\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2951\u001B[0m         desc\u001B[38;5;241m=\u001B[39mdesc \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMap\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   2952\u001B[0m     ) \u001B[38;5;28;01mas\u001B[39;00m pbar:\n\u001B[0;32m-> 2953\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m rank, done, content \u001B[38;5;129;01min\u001B[39;00m Dataset\u001B[38;5;241m.\u001B[39m_map_single(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mdataset_kwargs):\n\u001B[1;32m   2954\u001B[0m             \u001B[38;5;28;01mif\u001B[39;00m done:\n\u001B[1;32m   2955\u001B[0m                 shards_done \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py:3329\u001B[0m, in \u001B[0;36mDataset._map_single\u001B[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001B[0m\n\u001B[1;32m   3325\u001B[0m indices \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\n\u001B[1;32m   3326\u001B[0m     \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m*\u001B[39m(\u001B[38;5;28mslice\u001B[39m(i, i \u001B[38;5;241m+\u001B[39m batch_size)\u001B[38;5;241m.\u001B[39mindices(shard\u001B[38;5;241m.\u001B[39mnum_rows)))\n\u001B[1;32m   3327\u001B[0m )  \u001B[38;5;66;03m# Something simpler?\u001B[39;00m\n\u001B[1;32m   3328\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3329\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[43mapply_function_on_filtered_inputs\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   3330\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3331\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3332\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheck_same_num_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mshard\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlist_indexes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3333\u001B[0m \u001B[43m        \u001B[49m\u001B[43moffset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moffset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3334\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3335\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m NumExamplesMismatchError:\n\u001B[1;32m   3336\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m DatasetTransformationNotAllowedError(\n\u001B[1;32m   3337\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   3338\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/datasets/arrow_dataset.py:3210\u001B[0m, in \u001B[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001B[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001B[0m\n\u001B[1;32m   3208\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m with_rank:\n\u001B[1;32m   3209\u001B[0m     additional_args \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (rank,)\n\u001B[0;32m-> 3210\u001B[0m processed_inputs \u001B[38;5;241m=\u001B[39m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfn_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43madditional_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfn_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3211\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(processed_inputs, LazyDict):\n\u001B[1;32m   3212\u001B[0m     processed_inputs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m   3213\u001B[0m         k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m processed_inputs\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mitems() \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m processed_inputs\u001B[38;5;241m.\u001B[39mkeys_to_format\n\u001B[1;32m   3214\u001B[0m     }\n",
      "Input \u001B[0;32mIn [16]\u001B[0m, in \u001B[0;36mprocess_function\u001B[0;34m(examples)\u001B[0m\n\u001B[1;32m     27\u001B[0m             context\u001B[38;5;241m.\u001B[39mappend(ctx)\n\u001B[1;32m     28\u001B[0m             question_choice\u001B[38;5;241m.\u001B[39mappend(question \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m不知道\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 29\u001B[0m     labels\u001B[38;5;241m.\u001B[39mappend(\u001B[43mchoices\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexamples\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43manswer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;66;03m# import random\u001B[39;00m\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;66;03m# labels.append(random.randint(0,4))\u001B[39;00m\n\u001B[1;32m     32\u001B[0m tokenized_examples \u001B[38;5;241m=\u001B[39m tokenizer(context, question_choice, truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124monly_first\u001B[39m\u001B[38;5;124m\"\u001B[39m, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m, padding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmax_length\u001B[39m\u001B[38;5;124m\"\u001B[39m)     \u001B[38;5;66;03m# input_ids: 4000 * 256, \u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: '' is not in list"
     ]
    }
   ],
   "source": [
    "# 任务类：\n",
    "# 多项选择, AutoModelForMultipleChoice\n",
    "\n",
    "import evaluate\n",
    "from datasets import DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModelForMultipleChoice, TrainingArguments, Trainer\n",
    "model_dirpath = './models/roberta-base-finetuned-dianping-chinese'\n",
    "c3 = DatasetDict.load_from_disk(\"./data/c3/\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dirpath)\n",
    "def process_function(examples):\n",
    "    # examples, dict, keys: [\"context\", \"quesiton\", \"choice\", \"answer\"]\n",
    "    # examples, 1000\n",
    "    context = []\n",
    "    question_choice = []\n",
    "    labels = []\n",
    "    # print(examples.keys())\n",
    "    for idx in range(len(examples[\"context\"])):\n",
    "        # print(examples[\"context\"][idx], examples[\"question\"][idx], examples[\"choice\"][idx], examples[\"answer\"][idx])\n",
    "        ctx = \"\\n\".join(examples[\"context\"][idx])\n",
    "        question = examples[\"question\"][idx]\n",
    "        choices = examples[\"choice\"][idx]\n",
    "        for choice in choices:\n",
    "            context.append(ctx)\n",
    "            question_choice.append(question + \" \" + choice)\n",
    "        if len(choices) < 4:\n",
    "            for _ in range(4 - len(choices)):\n",
    "                context.append(ctx)\n",
    "                question_choice.append(question + \" \" + \"不知道\")\n",
    "        labels.append(choices.index(examples[\"answer\"][idx]))\n",
    "        # import random\n",
    "        # labels.append(random.randint(0,4))\n",
    "    tokenized_examples = tokenizer(context, question_choice, truncation=\"only_first\", max_length=256, padding=\"max_length\")     # input_ids: 4000 * 256, \n",
    "    tokenized_examples = {k: [v[i: i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}     # 1000 * 4 *256\n",
    "    tokenized_examples[\"labels\"] = labels\n",
    "    return tokenized_examples\n",
    "tokenized_c3 = c3.map(process_function, batched=True)\n",
    "model = AutoModelForMultipleChoice.from_pretrained(model_dirpath)\n",
    "import numpy as np\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "def compute_metric(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "args = TrainingArguments(output_dir=\"./muliple_choice\", per_device_train_batch_size=16, per_gpu_eval_batch_size=16, num_train_epochs=3,\n",
    "    logging_steps=50, evaluation_strategy=\"epoch\", save_strategy=\"epoch\", load_best_model_at_end=True, fp16=True)\n",
    "trainer = Trainer(model=model, args=args, train_dataset=tokenized_c3[\"train\"], eval_dataset=tokenized_c3[\"validation\"], compute_metrics=compute_metric)\n",
    "# trainer.train()\n",
    "\n",
    "from typing import Any\n",
    "import torch\n",
    "class MultipleChoicePipeline:\n",
    "    def __init__(self, model, tokenizer) -> None:\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = model.device\n",
    "    def preprocess(self, context, quesiton, choices):\n",
    "        cs, qcs = [], []\n",
    "        for choice in choices:\n",
    "            cs.append(context)\n",
    "            qcs.append(quesiton + \" \" + choice)\n",
    "        return tokenizer(cs, qcs, truncation=\"only_first\", max_length=256, return_tensors=\"pt\")\n",
    "    def predict(self, inputs):\n",
    "        inputs = {k: v.unsqueeze(0).to(self.device) for k, v in inputs.items()}\n",
    "        return self.model(**inputs).logits\n",
    "    def postprocess(self, logits, choices):\n",
    "        predition = torch.argmax(logits, dim=-1).cpu().item()\n",
    "        return choices[predition]\n",
    "    def __call__(self, context, question, choices) -> Any:\n",
    "        inputs = self.preprocess(context, question, choices)\n",
    "        logits = self.predict(inputs)\n",
    "        result = self.postprocess(logits, choices)\n",
    "        return result\n",
    "pipe = MultipleChoicePipeline(model, tokenizer)\n",
    "pipe(\"小明在北京上班\", \"小明在哪里上班？\", [\"北京\", \"上海\", \"河北\", \"海南\", \"河北\", \"海南\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T13:25:19.442147Z",
     "start_time": "2023-08-28T13:25:19.212740Z"
    }
   },
   "id": "86750532f0a5b9e6"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/fubin/.cache/huggingface/datasets/json/default-a04ab90bd0f58ecf/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cb7b118824a4a9db58b37121dbbecdc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f2ff5078a824185b0dbd07c68be8dbd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ./models/roberta-base-finetuned-dianping-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using the latest cached version of the module from /Users/fubin/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--accuracy/f887c0aab52c2d38e1f8a215681126379eca617f96c447638f751434e8e65b14 (last modified on Sun Aug 27 12:02:57 2023) since it couldn't be found locally at evaluate-metric--accuracy, or remotely on the Hugging Face Hub.\n",
      "/Users/fubin/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/1 : < :, Epoch 0.00/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 1/63 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'label': '不相似', 'score': 0.04445357993245125}"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 任务类：\n",
    "# 文本相似度：cross单塔模式，AutoModelForSequenceClassification\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import BertForSequenceClassification \n",
    "from datasets import load_dataset\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "dataset = load_dataset(\"json\", data_files=\"./data/train_pair_1w.json\", split=\"train\")\n",
    "datasets = dataset.train_test_split(test_size=0.2)\n",
    "model_dirpath = './models/roberta-base-finetuned-dianping-chinese'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dirpath)\n",
    "def process_function(examples):\n",
    "    tokenized_examples = tokenizer(examples[\"sentence1\"], examples[\"sentence2\"], max_length=128, truncation=True)\n",
    "    tokenized_examples[\"labels\"] = [float(label) for label in examples[\"label\"]]\n",
    "    return tokenized_examples\n",
    "tokenized_datasets = datasets.map(process_function, batched=True, remove_columns=datasets[\"train\"].column_names)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dirpath, num_labels=1)\n",
    "import evaluate\n",
    "acc_metric = evaluate.load(\"accuracy\")\n",
    "f1_metirc = evaluate.load(\"f1\")\n",
    "def eval_metric(eval_predict):\n",
    "    predictions, labels = eval_predict\n",
    "    predictions = [int(p > 0.5) for p in predictions]\n",
    "    labels = [int(l) for l in labels]\n",
    "    # predictions = predictions.argmax(axis=-1)\n",
    "    acc = acc_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metirc.compute(predictions=predictions, references=labels)\n",
    "    acc.update(f1)\n",
    "    return acc\n",
    "train_args = TrainingArguments(output_dir=\"./checkpoints/cross_model\",      # 输出文件夹\n",
    "                               per_device_train_batch_size=32,  # 训练时的batch_size\n",
    "                               per_device_eval_batch_size=32,  # 验证时的batch_size\n",
    "                               logging_steps=10,                # log 打印的频率\n",
    "                               evaluation_strategy=\"epoch\",     # 评估策略\n",
    "                               save_strategy=\"epoch\",           # 保存策略\n",
    "                               save_total_limit=3,              # 最大保存数\n",
    "                               learning_rate=2e-5,              # 学习率\n",
    "                               weight_decay=0.01,               # weight_decay\n",
    "                               metric_for_best_model=\"f1\",      # 设定评估指标\n",
    "                               max_steps=1,\n",
    "                               load_best_model_at_end=True)     # 训练完成后加载最优模型\n",
    "from transformers import DataCollatorWithPadding\n",
    "trainer = Trainer(model=model, args=train_args, train_dataset=tokenized_datasets[\"train\"], eval_dataset=tokenized_datasets[\"test\"], \n",
    "                  data_collator=DataCollatorWithPadding(tokenizer=tokenizer), compute_metrics=eval_metric)\n",
    "trainer.train()\n",
    "trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "from transformers import pipeline, TextClassificationPipeline\n",
    "model.config.id2label = {0: \"不相似\", 1: \"相似\"}\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer, device=device)\n",
    "result = pipe({\"text\": \"我喜欢北京\", \"text_pair\": \"天气怎样\"}, function_to_apply=\"none\")\n",
    "result[\"label\"] = \"相似\" if result[\"score\"] > 0.5 else \"不相似\"\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T13:41:05.575409Z",
     "start_time": "2023-08-28T13:38:00.835267Z"
    }
   },
   "id": "8ab96afee6f3afda"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/Users/fubin/.cache/huggingface/datasets/json/default-a04ab90bd0f58ecf/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4d4c5f26eaa48468dd97be38493728e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db28b86bf685462eb41f6c1c72516012"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /Users/fubin/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--f1/0ca73f6cf92ef5a268320c697f7b940d1030f8471714bffdb6856c641b818974 (last modified on Sun Aug 27 12:03:19 2023) since it couldn't be found locally at evaluate-metric--f1, or remotely on the Hugging Face Hub.\n",
      "/Users/fubin/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/1 : < :, Epoch 0.00/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "(-0.5986318588256836,\n tensor([[-0.8401,  0.0303, -0.1209,  ...,  0.1178,  0.1029,  0.7115],\n         [ 0.9445,  0.2606,  0.8640,  ...,  0.4961,  0.3653, -0.8795]],\n        device='mps:0', grad_fn=<TanhBackward0>))"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 任务类：\n",
    "# 文本相似度：dual 双塔模式\n",
    "# 实现：自定义 DualModel(BertPreTrainedModel)\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "dataset = load_dataset(\"json\", data_files=\"./data/train_pair_1w.json\", split=\"train\")\n",
    "datasets = dataset.train_test_split(test_size=0.2)\n",
    "model_dirpath = './models/roberta-base-finetuned-dianping-chinese'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dirpath)\n",
    "def process_function(examples):\n",
    "    sentences = []\n",
    "    labels = []\n",
    "    for sen1, sen2, label in zip(examples[\"sentence1\"], examples[\"sentence2\"], examples[\"label\"]):\n",
    "        sentences.append(sen1)\n",
    "        sentences.append(sen2)\n",
    "        labels.append(1 if int(label) == 1 else -1)\n",
    "    # input_ids, attention_mask, token_type_ids\n",
    "    tokenized_examples = tokenizer(sentences, max_length=128, truncation=True, padding=\"max_length\")\n",
    "    tokenized_examples = {k: [v[i: i + 2] for i in range(0, len(v), 2)] for k, v in tokenized_examples.items()}\n",
    "    tokenized_examples[\"labels\"] = labels\n",
    "    return tokenized_examples\n",
    "tokenized_datasets = datasets.map(process_function, batched=True, remove_columns=datasets[\"train\"].column_names)\n",
    "from transformers import BertForSequenceClassification, BertPreTrainedModel, BertModel\n",
    "from typing import Optional\n",
    "from transformers.configuration_utils import PretrainedConfig\n",
    "from torch.nn import CosineSimilarity, CosineEmbeddingLoss\n",
    "\n",
    "class DualModel(BertPreTrainedModel):\n",
    "    def __init__(self, config: PretrainedConfig, *inputs, **kwargs):\n",
    "        super().__init__(config, *inputs, **kwargs)\n",
    "        self.bert = BertModel(config)\n",
    "        self.post_init()\n",
    "    def forward(self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        # Step1 分别获取sentenceA 和 sentenceB的输入\n",
    "        senA_input_ids, senB_input_ids = input_ids[:, 0], input_ids[:, 1]\n",
    "        senA_attention_mask, senB_attention_mask = attention_mask[:, 0], attention_mask[:, 1]\n",
    "        senA_token_type_ids, senB_token_type_ids = token_type_ids[:, 0], token_type_ids[:, 1]\n",
    "        # Step2 分别获取sentenceA 和 sentenceB的向量表示\n",
    "        senA_outputs = self.bert(senA_input_ids, attention_mask=senA_attention_mask, token_type_ids=senA_token_type_ids, position_ids=position_ids,\n",
    "            head_mask=head_mask, inputs_embeds=inputs_embeds, output_attentions=output_attentions, output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,)\n",
    "        senA_pooled_output = senA_outputs[1]    # [batch, hidden]\n",
    "        senB_outputs = self.bert(senB_input_ids, attention_mask=senB_attention_mask, token_type_ids=senB_token_type_ids, position_ids=position_ids,\n",
    "            head_mask=head_mask, inputs_embeds=inputs_embeds, output_attentions=output_attentions, output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,)\n",
    "        senB_pooled_output = senB_outputs[1]    # [batch, hidden]\n",
    "        # step3 计算相似度\n",
    "        cos = CosineSimilarity()(senA_pooled_output, senB_pooled_output)    # [batch, ]\n",
    "        # step4 计算loss\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CosineEmbeddingLoss(0.3)\n",
    "            loss = loss_fct(senA_pooled_output, senB_pooled_output, labels)\n",
    "        output = (cos,)\n",
    "        return ((loss,) + output) if loss is not None else output\n",
    "model = DualModel.from_pretrained(model_dirpath)\n",
    "import evaluate\n",
    "acc_metric = evaluate.load(\"accuracy\")\n",
    "f1_metirc = evaluate.load(\"f1\")\n",
    "def eval_metric(eval_predict):\n",
    "    predictions, labels = eval_predict\n",
    "    predictions = [int(p > 0.7) for p in predictions]\n",
    "    labels = [int(l > 0) for l in labels]\n",
    "    # predictions = predictions.argmax(axis=-1)\n",
    "    acc = acc_metric.compute(predictions=predictions, references=labels)\n",
    "    f1 = f1_metirc.compute(predictions=predictions, references=labels)\n",
    "    acc.update(f1)\n",
    "    return acc\n",
    "train_args = TrainingArguments(output_dir=\"./checkpoints/dual_model\",      # 输出文件夹\n",
    "                               per_device_train_batch_size=32,  # 训练时的batch_size\n",
    "                               per_device_eval_batch_size=32,  # 验证时的batch_size\n",
    "                               logging_steps=10,                # log 打印的频率\n",
    "                               evaluation_strategy=\"epoch\",     # 评估策略\n",
    "                               save_strategy=\"epoch\",           # 保存策略\n",
    "                               save_total_limit=3,              # 最大保存数\n",
    "                               learning_rate=2e-5,              # 学习率\n",
    "                               weight_decay=0.01,               # weight_decay\n",
    "                               metric_for_best_model=\"f1\",      # 设定评估指标\n",
    "                               max_steps=1,\n",
    "                               load_best_model_at_end=True)     # 训练完成后加载最优模型\n",
    "trainer = Trainer(model=model,  args=train_args,  train_dataset=tokenized_datasets[\"train\"],  eval_dataset=tokenized_datasets[\"test\"],  compute_metrics=eval_metric)\n",
    "trainer.train()\n",
    "class SentenceSimilarityPipeline:\n",
    "    def __init__(self, model, tokenizer) -> None:\n",
    "        self.model = model.bert\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = model.device\n",
    "    def preprocess(self, senA, senB):\n",
    "        return self.tokenizer([senA, senB], max_length=128, truncation=True, return_tensors=\"pt\", padding=True)\n",
    "    def predict(self, inputs):\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        return self.model(**inputs)[1]  # [2, 768]\n",
    "    def postprocess(self, logits):\n",
    "        cos = CosineSimilarity()(logits[None, 0, :], logits[None,1, :]).squeeze().cpu().item()\n",
    "        return cos\n",
    "    def __call__(self, senA, senB, return_vector=False):\n",
    "        inputs = self.preprocess(senA, senB)\n",
    "        logits = self.predict(inputs)\n",
    "        result = self.postprocess(logits)\n",
    "        if return_vector:\n",
    "            return result, logits\n",
    "        else:\n",
    "            return result\n",
    "pipe = SentenceSimilarityPipeline(model, tokenizer)\n",
    "pipe(\"我喜欢北京\", \"明天不行\", return_vector=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T13:45:36.675280Z",
     "start_time": "2023-08-28T13:42:20.605528Z"
    }
   },
   "id": "501bf1b903947beb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 136/570 [02:18<07:20,  1.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# 任务类：\n",
    "# 检索式聊天机器人：dual 双塔模式\n",
    "# 实现：自定义 DualModel(BertPreTrainedModel)\n",
    "# 双塔向量召回（faiss）+ 单塔召回\n",
    "\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, BertPreTrainedModel, BertModel\n",
    "from typing import Optional\n",
    "from transformers.configuration_utils import PretrainedConfig\n",
    "from torch.nn import CosineSimilarity, CosineEmbeddingLoss\n",
    "model_dirpath = './models/roberta-base-finetuned-dianping-chinese'\n",
    "\n",
    "class DualModel(BertPreTrainedModel):\n",
    "    def __init__(self, config: PretrainedConfig, *inputs, **kwargs):\n",
    "        super().__init__(config, *inputs, **kwargs)\n",
    "        self.bert = BertModel(config)\n",
    "        self.post_init()\n",
    "    def forward(self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        # Step1 分别获取sentenceA 和 sentenceB的输入\n",
    "        senA_input_ids, senB_input_ids = input_ids[:, 0], input_ids[:, 1]\n",
    "        senA_attention_mask, senB_attention_mask = attention_mask[:, 0], attention_mask[:, 1]\n",
    "        senA_token_type_ids, senB_token_type_ids = token_type_ids[:, 0], token_type_ids[:, 1]\n",
    "        # Step2 分别获取sentenceA 和 sentenceB的向量表示\n",
    "        senA_outputs = self.bert(senA_input_ids, attention_mask=senA_attention_mask, token_type_ids=senA_token_type_ids, position_ids=position_ids,\n",
    "            head_mask=head_mask, inputs_embeds=inputs_embeds, output_attentions=output_attentions, output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,)\n",
    "        senA_pooled_output = senA_outputs[1]    # [batch, hidden]\n",
    "        senB_outputs = self.bert(senB_input_ids, attention_mask=senB_attention_mask, token_type_ids=senB_token_type_ids, position_ids=position_ids,\n",
    "            head_mask=head_mask, inputs_embeds=inputs_embeds, output_attentions=output_attentions, output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,)\n",
    "        senB_pooled_output = senB_outputs[1]    # [batch, hidden]\n",
    "        # step3 计算相似度\n",
    "        cos = CosineSimilarity()(senA_pooled_output, senB_pooled_output)    # [batch, ]\n",
    "        # step4 计算loss\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CosineEmbeddingLoss(0.3)\n",
    "            loss = loss_fct(senA_pooled_output, senB_pooled_output, labels)\n",
    "        output = (cos,)\n",
    "        return ((loss,) + output) if loss is not None else output\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"./data/law_faq.csv\")\n",
    "dual_model = DualModel.from_pretrained(model_dirpath)\n",
    "dual_model.eval()\n",
    "from transformers import AutoTokenizer\n",
    "tokenzier = AutoTokenizer.from_pretrained(model_dirpath)\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "questions = data[\"title\"].to_list()\n",
    "vectors = []\n",
    "with torch.inference_mode():\n",
    "    for i in tqdm(range(0, len(questions), 32)):\n",
    "        batch_sens = questions[i: i + 32]\n",
    "        inputs = tokenzier(batch_sens, return_tensors=\"pt\", padding=True, max_length=128, truncation=True)\n",
    "        inputs = {k: v.to(dual_model.device) for k, v in inputs.items()}\n",
    "        vector = dual_model.bert(**inputs)[1]\n",
    "        vectors.append(vector)\n",
    "vectors = torch.concat(vectors, dim=0).cpu().numpy()\n",
    "# 构建faiss向量检索:近似近邻检索库，支持10亿级别的向量检索，最成熟的近似近邻检索库\n",
    "# 向量集合大小由内存决定，C++编写，适合大数据量高维快速检索（ms级别），工程上很好。\n",
    "import faiss\n",
    "index = faiss.IndexFlatIP(768)\n",
    "faiss.normalize_L2(vectors)\n",
    "index.add(vectors) # 建立索引\n",
    "quesiton = \"寻衅滋事\"\n",
    "with torch.inference_mode():\n",
    "    inputs = tokenzier(quesiton, return_tensors=\"pt\", padding=True, max_length=128, truncation=True)\n",
    "    inputs = {k: v.to(dual_model.device) for k, v in inputs.items()}\n",
    "    vector = dual_model.bert(**inputs)[1]\n",
    "    q_vector = vector.cpu().numpy()\n",
    "# 向量匹配(召回)\n",
    "faiss.normalize_L2(q_vector)\n",
    "scores, indexes = index.search(q_vector, 10) # 检索\n",
    "topk_result = data.values[indexes[0].tolist()]\n",
    "topk_result[:, 0]\n",
    "# 加载单塔模型进行精细排序：效果好\n",
    "from transformers import BertForSequenceClassification\n",
    "corss_model = BertForSequenceClassification.from_pretrained(\"./data/cross_model/checkpoint-1/\")\n",
    "corss_model = corss_model.cuda()\n",
    "corss_model.eval()\n",
    "canidate = topk_result[:, 0].tolist()\n",
    "ques = [quesiton] * len(canidate)\n",
    "inputs = tokenzier(ques, canidate, return_tensors=\"pt\", padding=True, max_length=128, truncation=True)\n",
    "inputs = {k: v.to(corss_model.device) for k, v in inputs.items()}\n",
    "with torch.inference_mode():\n",
    "    logits = corss_model(**inputs).logits.squeeze()\n",
    "    result = torch.argmax(logits, dim=-1)\n",
    "canidate_answer = topk_result[:, 1].tolist()\n",
    "match_quesiton = canidate[result.item()]\n",
    "final_answer = canidate_answer[result.item()]\n",
    "match_quesiton, final_answer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-28T13:52:45.461549Z"
    }
   },
   "id": "381271f3881286b6"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "(MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /hfl/chinese-macbert-base/resolve/main/tokenizer_config.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\"), '(Request ID: d1a3fa3b-2b21-402e-ad78-5b709e61af66)')",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mSSLEOFError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:667\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    666\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_new_proxy_conn:\n\u001B[0;32m--> 667\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_proxy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:932\u001B[0m, in \u001B[0;36mHTTPSConnectionPool._prepare_proxy\u001B[0;34m(self, conn)\u001B[0m\n\u001B[1;32m    931\u001B[0m conn\u001B[38;5;241m.\u001B[39mset_tunnel(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_proxy_host, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mport, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mproxy_headers)\n\u001B[0;32m--> 932\u001B[0m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connection.py:362\u001B[0m, in \u001B[0;36mHTTPSConnection.connect\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    360\u001B[0m     context\u001B[38;5;241m.\u001B[39mload_default_certs()\n\u001B[0;32m--> 362\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock \u001B[38;5;241m=\u001B[39m \u001B[43mssl_wrap_socket\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    363\u001B[0m \u001B[43m    \u001B[49m\u001B[43msock\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    364\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeyfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkey_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    365\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcertfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcert_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    366\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkey_password\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkey_password\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    367\u001B[0m \u001B[43m    \u001B[49m\u001B[43mca_certs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mca_certs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    368\u001B[0m \u001B[43m    \u001B[49m\u001B[43mca_cert_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mca_cert_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    369\u001B[0m \u001B[43m    \u001B[49m\u001B[43mca_cert_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mca_cert_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    370\u001B[0m \u001B[43m    \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    371\u001B[0m \u001B[43m    \u001B[49m\u001B[43mssl_context\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcontext\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    372\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    374\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39massert_fingerprint:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/util/ssl_.py:386\u001B[0m, in \u001B[0;36mssl_wrap_socket\u001B[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data)\u001B[0m\n\u001B[1;32m    385\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m HAS_SNI \u001B[38;5;129;01mand\u001B[39;00m server_hostname \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 386\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcontext\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrap_socket\u001B[49m\u001B[43m(\u001B[49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    388\u001B[0m warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    389\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn HTTPS request has been made, but the SNI (Server Name \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    390\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIndication) extension to TLS is not available on this platform. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    396\u001B[0m     SNIMissingWarning,\n\u001B[1;32m    397\u001B[0m )\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/ssl.py:501\u001B[0m, in \u001B[0;36mSSLContext.wrap_socket\u001B[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001B[0m\n\u001B[1;32m    495\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrap_socket\u001B[39m(\u001B[38;5;28mself\u001B[39m, sock, server_side\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    496\u001B[0m                 do_handshake_on_connect\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    497\u001B[0m                 suppress_ragged_eofs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    498\u001B[0m                 server_hostname\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, session\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    499\u001B[0m     \u001B[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001B[39;00m\n\u001B[1;32m    500\u001B[0m     \u001B[38;5;66;03m# ctx._wrap_socket()\u001B[39;00m\n\u001B[0;32m--> 501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msslsocket_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_create\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43msock\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msock\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserver_side\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_side\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdo_handshake_on_connect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdo_handshake_on_connect\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    505\u001B[0m \u001B[43m        \u001B[49m\u001B[43msuppress_ragged_eofs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msuppress_ragged_eofs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    506\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserver_hostname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserver_hostname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    507\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[43m        \u001B[49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msession\u001B[49m\n\u001B[1;32m    509\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/ssl.py:1041\u001B[0m, in \u001B[0;36mSSLSocket._create\u001B[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001B[0m\n\u001B[1;32m   1040\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1041\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_handshake\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1042\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mOSError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/ssl.py:1310\u001B[0m, in \u001B[0;36mSSLSocket.do_handshake\u001B[0;34m(self, block)\u001B[0m\n\u001B[1;32m   1309\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msettimeout(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m-> 1310\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdo_handshake\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1311\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[0;31mSSLEOFError\u001B[0m: EOF occurred in violation of protocol (_ssl.c:1129)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mMaxRetryError\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py:440\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    439\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m chunked:\n\u001B[0;32m--> 440\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    441\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    442\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    444\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    445\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    446\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    447\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    448\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    449\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    450\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\n\u001B[1;32m    451\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    453\u001B[0m \u001B[38;5;66;03m# Send the request.\u001B[39;00m\n\u001B[1;32m    454\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:726\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    724\u001B[0m     e \u001B[38;5;241m=\u001B[39m ProtocolError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection aborted.\u001B[39m\u001B[38;5;124m\"\u001B[39m, e)\n\u001B[0;32m--> 726\u001B[0m retries \u001B[38;5;241m=\u001B[39m \u001B[43mretries\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mincrement\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    727\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacktrace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexc_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m    728\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    729\u001B[0m retries\u001B[38;5;241m.\u001B[39msleep()\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py:446\u001B[0m, in \u001B[0;36mRetry.increment\u001B[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n\u001B[1;32m    445\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m new_retry\u001B[38;5;241m.\u001B[39mis_exhausted():\n\u001B[0;32m--> 446\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MaxRetryError(_pool, url, error \u001B[38;5;129;01mor\u001B[39;00m ResponseError(cause))\n\u001B[1;32m    448\u001B[0m log\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncremented Retry for (url=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m): \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, url, new_retry)\n",
      "\u001B[0;31mMaxRetryError\u001B[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /hfl/chinese-macbert-base/resolve/main/tokenizer_config.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mSSLError\u001B[0m                                  Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 8>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      6\u001B[0m ds \u001B[38;5;241m=\u001B[39m Dataset\u001B[38;5;241m.\u001B[39mload_from_disk(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./data/wiki_cn_filtered/\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      7\u001B[0m model_dirpath \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhfl/chinese-macbert-base\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 8\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m \u001B[43mAutoTokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_dirpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mprocess_func\u001B[39m(examples):\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tokenizer(examples[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompletion\u001B[39m\u001B[38;5;124m\"\u001B[39m], max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m384\u001B[39m, truncation\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:652\u001B[0m, in \u001B[0;36mAutoTokenizer.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    649\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tokenizer_class\u001B[38;5;241m.\u001B[39mfrom_pretrained(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    651\u001B[0m \u001B[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001B[39;00m\n\u001B[0;32m--> 652\u001B[0m tokenizer_config \u001B[38;5;241m=\u001B[39m \u001B[43mget_tokenizer_config\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    653\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m tokenizer_config:\n\u001B[1;32m    654\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m tokenizer_config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py:496\u001B[0m, in \u001B[0;36mget_tokenizer_config\u001B[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, **kwargs)\u001B[0m\n\u001B[1;32m    434\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    435\u001B[0m \u001B[38;5;124;03mLoads the tokenizer configuration from a pretrained model tokenizer configuration.\u001B[39;00m\n\u001B[1;32m    436\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    493\u001B[0m \u001B[38;5;124;03mtokenizer_config = get_tokenizer_config(\"tokenizer-test\")\u001B[39;00m\n\u001B[1;32m    494\u001B[0m \u001B[38;5;124;03m```\"\"\"\u001B[39;00m\n\u001B[1;32m    495\u001B[0m commit_hash \u001B[38;5;241m=\u001B[39m kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_commit_hash\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m--> 496\u001B[0m resolved_config_file \u001B[38;5;241m=\u001B[39m \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m    \u001B[49m\u001B[43mTOKENIZER_CONFIG_FILE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    503\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    505\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    506\u001B[0m \u001B[43m    \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    507\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_raise_exceptions_for_missing_entries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    508\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_raise_exceptions_for_connection_errors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    509\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    510\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m resolved_config_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    512\u001B[0m     logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/hub.py:417\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001B[0m\n\u001B[1;32m    414\u001B[0m user_agent \u001B[38;5;241m=\u001B[39m http_user_agent(user_agent)\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    416\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[0;32m--> 417\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    418\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    419\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    420\u001B[0m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    421\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    422\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    423\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    424\u001B[0m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    425\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    426\u001B[0m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    427\u001B[0m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_auth_token\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_auth_token\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    429\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    430\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RepositoryNotFoundError:\n\u001B[1;32m    433\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEnvironmentError\u001B[39;00m(\n\u001B[1;32m    434\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m is not a local folder and is not a valid model identifier \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    435\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlisted on \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://huggingface.co/models\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mIf this is a private repository, make sure to \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    436\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    437\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    438\u001B[0m     )\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:118\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    116\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1195\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001B[0m\n\u001B[1;32m   1193\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1194\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1195\u001B[0m         metadata \u001B[38;5;241m=\u001B[39m \u001B[43mget_hf_file_metadata\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1196\u001B[0m \u001B[43m            \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1197\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtoken\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1198\u001B[0m \u001B[43m            \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1199\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43metag_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1200\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1201\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m EntryNotFoundError \u001B[38;5;28;01mas\u001B[39;00m http_error:\n\u001B[1;32m   1202\u001B[0m         \u001B[38;5;66;03m# Cache the non-existence of the file and raise\u001B[39;00m\n\u001B[1;32m   1203\u001B[0m         commit_hash \u001B[38;5;241m=\u001B[39m http_error\u001B[38;5;241m.\u001B[39mresponse\u001B[38;5;241m.\u001B[39mheaders\u001B[38;5;241m.\u001B[39mget(HUGGINGFACE_HEADER_X_REPO_COMMIT)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/utils/_validators.py:118\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    116\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 118\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:1532\u001B[0m, in \u001B[0;36mget_hf_file_metadata\u001B[0;34m(url, token, proxies, timeout)\u001B[0m\n\u001B[1;32m   1529\u001B[0m headers[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccept-Encoding\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124midentity\u001B[39m\u001B[38;5;124m\"\u001B[39m  \u001B[38;5;66;03m# prevent any compression => we want to know the real size of the file\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;66;03m# Retrieve metadata\u001B[39;00m\n\u001B[0;32m-> 1532\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43m_request_wrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1533\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mHEAD\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1534\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1535\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1536\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1537\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfollow_relative_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   1538\u001B[0m \u001B[43m    \u001B[49m\u001B[43mproxies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1539\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1540\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1541\u001B[0m hf_raise_for_status(r)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;66;03m# Return\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:407\u001B[0m, in \u001B[0;36m_request_wrapper\u001B[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001B[0m\n\u001B[1;32m    405\u001B[0m \u001B[38;5;66;03m# 2. Force relative redirection\u001B[39;00m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m follow_relative_redirects:\n\u001B[0;32m--> 407\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43m_request_wrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    408\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    409\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    410\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    411\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbase_wait_time\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_wait_time\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    412\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_wait_time\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_wait_time\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    413\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    414\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfollow_relative_redirects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    415\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;66;03m# If redirection, we redirect only relative paths.\u001B[39;00m\n\u001B[1;32m    419\u001B[0m     \u001B[38;5;66;03m# This is useful in case of a renamed repository.\u001B[39;00m\n\u001B[1;32m    420\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;241m300\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m399\u001B[39m:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py:442\u001B[0m, in \u001B[0;36m_request_wrapper\u001B[0;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001B[0m\n\u001B[1;32m    439\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n\u001B[1;32m    441\u001B[0m \u001B[38;5;66;03m# 3. Exponential backoff\u001B[39;00m\n\u001B[0;32m--> 442\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mhttp_backoff\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    443\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    444\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    445\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    446\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbase_wait_time\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbase_wait_time\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    447\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_wait_time\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_wait_time\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    448\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretry_on_exceptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mTimeout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mProxyError\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    449\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretry_on_status_codes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    450\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    451\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    452\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/utils/_http.py:258\u001B[0m, in \u001B[0;36mhttp_backoff\u001B[0;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001B[0m\n\u001B[1;32m    255\u001B[0m     kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mseek(io_obj_initial_pos)\n\u001B[1;32m    257\u001B[0m \u001B[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001B[39;00m\n\u001B[0;32m--> 258\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m response\u001B[38;5;241m.\u001B[39mstatus_code \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m retry_on_status_codes:\n\u001B[1;32m    260\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:529\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    524\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    525\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m'\u001B[39m: timeout,\n\u001B[1;32m    526\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m'\u001B[39m: allow_redirects,\n\u001B[1;32m    527\u001B[0m }\n\u001B[1;32m    528\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 529\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:645\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    642\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    644\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 645\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    647\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    648\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/utils/_http.py:63\u001B[0m, in \u001B[0;36mUniqueRequestIdAdapter.send\u001B[0;34m(self, request, *args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;124;03m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001B[39;00m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 63\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mRequestException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     65\u001B[0m     request_id \u001B[38;5;241m=\u001B[39m request\u001B[38;5;241m.\u001B[39mheaders\u001B[38;5;241m.\u001B[39mget(X_AMZN_TRACE_ID)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py:517\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    513\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ProxyError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[1;32m    515\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e\u001B[38;5;241m.\u001B[39mreason, _SSLError):\n\u001B[1;32m    516\u001B[0m         \u001B[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001B[39;00m\n\u001B[0;32m--> 517\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m SSLError(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[1;32m    519\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(e, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[1;32m    521\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ClosedPoolError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mSSLError\u001B[0m: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /hfl/chinese-macbert-base/resolve/main/tokenizer_config.json (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1129)')))\"), '(Request ID: d1a3fa3b-2b21-402e-ad78-5b709e61af66)')"
     ]
    }
   ],
   "source": [
    "# 掩码语言模型: AutoModelForMaskedLM\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "ds = Dataset.load_from_disk(\"./data/wiki_cn_filtered/\")\n",
    "model_dirpath = 'hfl/chinese-macbert-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dirpath)\n",
    "def process_func(examples):\n",
    "    return tokenizer(examples[\"completion\"], max_length=384, truncation=True)\n",
    "tokenized_ds = ds.map(process_func, batched=True, remove_columns=ds.column_names)\n",
    "dl = DataLoader(tokenized_ds, batch_size=2, collate_fn=DataCollatorForLanguageModeling(tokenizer, mlm=True, mlm_probability=0.15))\n",
    "tokenizer.mask_token, tokenizer.mask_token_id\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_dirpath)\n",
    "args = TrainingArguments(output_dir=\"./models/masked_lm\", per_device_train_batch_size=32, logging_steps=10, num_train_epochs=1)\n",
    "trainer = Trainer(args=args, model=model, train_dataset=tokenized_ds, data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=True, mlm_probability=0.15))\n",
    "# trainer.train()\n",
    "\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"fill-mask\", model=model, tokenizer=tokenizer, device=device)\n",
    "pipe(\"西安交通[MASK][MASK]博物馆（Xi'an Jiaotong University Museum）是一座位于西安交通大学的博物馆\")\n",
    "pipe(\"下面是一则[MASK][MASK]新闻。小编报道，近日，游戏产业发展的非常好！\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:28:44.490573Z",
     "start_time": "2023-08-28T14:28:30.672350Z"
    }
   },
   "id": "2179b8a7fa9e0318"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/fubin/Downloads/复习/NLP/src/data/wiki_cn_filtered/cache-b0524261b02581a2.arrow\n",
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n",
      "/Users/fubin/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:725: UserWarning: MPS: no support for int64 repeats mask, casting it to int32 (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/mps/operations/Repeat.mm:236.)\n",
      "  input_ids = input_ids.repeat_interleave(expand_size, dim=0)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "MPS does not support cumsum op with int64 input",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[0;32mIn [5]\u001B[0m, in \u001B[0;36m<cell line: 24>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pipeline\n\u001B[1;32m     23\u001B[0m pipe \u001B[38;5;241m=\u001B[39m pipeline(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext-generation\u001B[39m\u001B[38;5;124m\"\u001B[39m, model\u001B[38;5;241m=\u001B[39mmodel, tokenizer\u001B[38;5;241m=\u001B[39mtokenizer, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[0;32m---> 24\u001B[0m \u001B[43mpipe\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m西安交通大学博物馆（Xi\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43man Jiaotong University Museum）是一座位于西安\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdo_sample\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     25\u001B[0m pipe(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m下面是一则游戏新闻。小编报道，近日，游戏产业发展的非常\u001B[39m\u001B[38;5;124m\"\u001B[39m, max_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m128\u001B[39m, do_sample\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/text_generation.py:200\u001B[0m, in \u001B[0;36mTextGenerationPipeline.__call__\u001B[0;34m(self, text_inputs, **kwargs)\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, text_inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    161\u001B[0m \u001B[38;5;124;03m    Complete the prompt(s) given as inputs.\u001B[39;00m\n\u001B[1;32m    162\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;124;03m          ids of the generated text.\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtext_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py:1122\u001B[0m, in \u001B[0;36mPipeline.__call__\u001B[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[1;32m   1115\u001B[0m         \u001B[38;5;28miter\u001B[39m(\n\u001B[1;32m   1116\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_iterator(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1119\u001B[0m         )\n\u001B[1;32m   1120\u001B[0m     )\n\u001B[1;32m   1121\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1122\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py:1129\u001B[0m, in \u001B[0;36mPipeline.run_single\u001B[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[0m\n\u001B[1;32m   1127\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_single\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001B[1;32m   1128\u001B[0m     model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(inputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpreprocess_params)\n\u001B[0;32m-> 1129\u001B[0m     model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1130\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpostprocess(model_outputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpostprocess_params)\n\u001B[1;32m   1131\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/base.py:1028\u001B[0m, in \u001B[0;36mPipeline.forward\u001B[0;34m(self, model_inputs, **forward_params)\u001B[0m\n\u001B[1;32m   1026\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m inference_context():\n\u001B[1;32m   1027\u001B[0m         model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_inputs, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m-> 1028\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mforward_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1029\u001B[0m         model_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ensure_tensor_on_device(model_outputs, device\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mdevice(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m   1030\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/pipelines/text_generation.py:261\u001B[0m, in \u001B[0;36mTextGenerationPipeline._forward\u001B[0;34m(self, model_inputs, **generate_kwargs)\u001B[0m\n\u001B[1;32m    258\u001B[0m         generate_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmin_length\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m prefix_length\n\u001B[1;32m    260\u001B[0m \u001B[38;5;66;03m# BS x SL\u001B[39;00m\n\u001B[0;32m--> 261\u001B[0m generated_sequence \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mgenerate_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    262\u001B[0m out_b \u001B[38;5;241m=\u001B[39m generated_sequence\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    263\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1588\u001B[0m, in \u001B[0;36mGenerationMixin.generate\u001B[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, **kwargs)\u001B[0m\n\u001B[1;32m   1580\u001B[0m     input_ids, model_kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_expand_inputs_for_generation(\n\u001B[1;32m   1581\u001B[0m         input_ids\u001B[38;5;241m=\u001B[39minput_ids,\n\u001B[1;32m   1582\u001B[0m         expand_size\u001B[38;5;241m=\u001B[39mgeneration_config\u001B[38;5;241m.\u001B[39mnum_return_sequences,\n\u001B[1;32m   1583\u001B[0m         is_encoder_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mis_encoder_decoder,\n\u001B[1;32m   1584\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs,\n\u001B[1;32m   1585\u001B[0m     )\n\u001B[1;32m   1587\u001B[0m     \u001B[38;5;66;03m# 13. run sample\u001B[39;00m\n\u001B[0;32m-> 1588\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1589\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1590\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_processor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogits_processor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1591\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlogits_warper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlogits_warper\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1592\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstopping_criteria\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstopping_criteria\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1593\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpad_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpad_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1594\u001B[0m \u001B[43m        \u001B[49m\u001B[43meos_token_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meos_token_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1595\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_scores\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moutput_scores\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1596\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgeneration_config\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreturn_dict_in_generate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1597\u001B[0m \u001B[43m        \u001B[49m\u001B[43msynced_gpus\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynced_gpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1598\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstreamer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstreamer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1599\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1600\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1602\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_beam_gen_mode:\n\u001B[1;32m   1603\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m generation_config\u001B[38;5;241m.\u001B[39mnum_return_sequences \u001B[38;5;241m>\u001B[39m generation_config\u001B[38;5;241m.\u001B[39mnum_beams:\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:2642\u001B[0m, in \u001B[0;36mGenerationMixin.sample\u001B[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001B[0m\n\u001B[1;32m   2639\u001B[0m model_inputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprepare_inputs_for_generation(input_ids, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mmodel_kwargs)\n\u001B[1;32m   2641\u001B[0m \u001B[38;5;66;03m# forward pass to get next token\u001B[39;00m\n\u001B[0;32m-> 2642\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2643\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mmodel_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2644\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m   2645\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2646\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2647\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2649\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m synced_gpus \u001B[38;5;129;01mand\u001B[39;00m this_peer_finished:\n\u001B[1;32m   2650\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m  \u001B[38;5;66;03m# don't waste resources running the code we don't need\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/bloom/modeling_bloom.py:908\u001B[0m, in \u001B[0;36mBloomForCausalLM.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, **deprecated_arguments)\u001B[0m\n\u001B[1;32m    904\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGot unexpected arguments: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdeprecated_arguments\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    906\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m--> 908\u001B[0m transformer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    909\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    910\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    911\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    912\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    913\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    914\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    915\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    916\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    917\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    918\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    919\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m transformer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    921\u001B[0m lm_logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlm_head(hidden_states)\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/bloom/modeling_bloom.py:751\u001B[0m, in \u001B[0;36mBloomModel.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, **deprecated_arguments)\u001B[0m\n\u001B[1;32m    748\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    749\u001B[0m     attention_mask \u001B[38;5;241m=\u001B[39m attention_mask\u001B[38;5;241m.\u001B[39mto(hidden_states\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m--> 751\u001B[0m alibi \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild_alibi_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_heads\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhidden_states\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    753\u001B[0m causal_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_attn_mask(\n\u001B[1;32m    754\u001B[0m     attention_mask,\n\u001B[1;32m    755\u001B[0m     input_shape\u001B[38;5;241m=\u001B[39m(batch_size, seq_length),\n\u001B[1;32m    756\u001B[0m     past_key_values_length\u001B[38;5;241m=\u001B[39mpast_key_values_length,\n\u001B[1;32m    757\u001B[0m )\n\u001B[1;32m    759\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (block, layer_past) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mh, past_key_values)):\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/bloom/modeling_bloom.py:640\u001B[0m, in \u001B[0;36mBloomModel.build_alibi_tensor\u001B[0;34m(self, attention_mask, num_heads, dtype)\u001B[0m\n\u001B[1;32m    639\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbuild_alibi_tensor\u001B[39m(\u001B[38;5;28mself\u001B[39m, attention_mask: torch\u001B[38;5;241m.\u001B[39mTensor, num_heads: \u001B[38;5;28mint\u001B[39m, dtype: torch\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m--> 640\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbuild_alibi_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_heads\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/bloom/modeling_bloom.py:125\u001B[0m, in \u001B[0;36mbuild_alibi_tensor\u001B[0;34m(attention_mask, num_heads, dtype)\u001B[0m\n\u001B[1;32m    117\u001B[0m     slopes \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([slopes, torch\u001B[38;5;241m.\u001B[39mpow(extra_base, extra_powers)], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    119\u001B[0m \u001B[38;5;66;03m# Note: alibi will added to the attention bias that will be applied to the query, key product of attention\u001B[39;00m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;66;03m# => therefore alibi will have to be of shape (batch_size, num_heads, query_length, key_length)\u001B[39;00m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;66;03m# => here we set (batch_size=1, num_heads=num_heads, query_length=1, key_length=max_length)\u001B[39;00m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;66;03m# => the query_length dimension will then be broadcasted correctly\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# This is more or less identical to T5's relative position bias:\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;66;03m# https://github.com/huggingface/transformers/blob/f681437203baa7671de3174b0fa583c349d9d5e1/src/transformers/models/t5/modeling_t5.py#L527\u001B[39;00m\n\u001B[0;32m--> 125\u001B[0m arange_tensor \u001B[38;5;241m=\u001B[39m ((\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcumsum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m*\u001B[39m attention_mask)[:, \u001B[38;5;28;01mNone\u001B[39;00m, :]\n\u001B[1;32m    126\u001B[0m alibi \u001B[38;5;241m=\u001B[39m slopes[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m] \u001B[38;5;241m*\u001B[39m arange_tensor\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m alibi\u001B[38;5;241m.\u001B[39mreshape(batch_size \u001B[38;5;241m*\u001B[39m num_heads, \u001B[38;5;241m1\u001B[39m, seq_length)\u001B[38;5;241m.\u001B[39mto(dtype)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: MPS does not support cumsum op with int64 input"
     ]
    }
   ],
   "source": [
    "# 因果语言模型：AutoModelForCausalLM\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else ('mps:0' if torch.backends.mps.is_available() else \"cpu\"))\n",
    "ds = Dataset.load_from_disk(\"./data/wiki_cn_filtered/\")\n",
    "model_dirpath = \"Langboat/bloom-389m-zh\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dirpath)\n",
    "def process_func(examples):\n",
    "    contents = [e + tokenizer.eos_token for e in examples[\"completion\"]]\n",
    "    return tokenizer(contents, max_length=384, truncation=True)\n",
    "tokenized_ds = ds.map(process_func, batched=True, remove_columns=ds.column_names)\n",
    "dl = DataLoader(tokenized_ds, batch_size=2, collate_fn=DataCollatorForLanguageModeling(tokenizer, mlm=False))\n",
    "tokenizer.pad_token, tokenizer.pad_token_id\n",
    "model = AutoModelForCausalLM.from_pretrained(model_dirpath)\n",
    "args = TrainingArguments(output_dir=\"./causal_lm\", per_device_train_batch_size=4, gradient_accumulation_steps=8,\n",
    "    logging_steps=10, num_train_epochs=1)\n",
    "trainer = Trainer(args=args, model=model, train_dataset=tokenized_ds, data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False))\n",
    "# trainer.train()\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=device)\n",
    "pipe(\"西安交通大学博物馆（Xi'an Jiaotong University Museum）是一座位于西安\", max_length=128, do_sample=True)\n",
    "pipe(\"下面是一则游戏新闻。小编报道，近日，游戏产业发展的非常\", max_length=128, do_sample=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-28T14:33:50.253153Z",
     "start_time": "2023-08-28T14:33:34.329554Z"
    }
   },
   "id": "e3827ac6ae07c593"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 文本摘要\n",
    "# 基于T5的文本摘要： AutoModelForSeq2SeqLM，Seq2SeqTrainer， Seq2SeqTrainingArguments\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "ds = Dataset.load_from_disk(\"./data/nlpcc_2017/\")\n",
    "ds = ds.train_test_split(100, seed=42)\n",
    "model_dirpath = \"Langboat/mengzi-t5-base\"\n",
    "tokenzier = AutoTokenizer.from_pretrained(model_dirpath)\n",
    "def process_func(exmaples):\n",
    "    contents = [\"摘要生成: \\n\" + e for e in exmaples[\"content\"]]\n",
    "    inputs = tokenzier(contents, max_length=384, truncation=True)\n",
    "    labels = tokenzier(text_target=exmaples[\"title\"], max_length=64, truncation=True)\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "tokenized_ds = ds.map(process_func, batched=True)\n",
    "tokenzier.decode(tokenized_ds[\"train\"][0][\"input_ids\"])\n",
    "tokenzier.decode(tokenized_ds[\"train\"][0][\"labels\"])\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_dirpath)\n",
    "\n",
    "import numpy as np\n",
    "from rouge_chinese import Rouge\n",
    "rouge = Rouge()\n",
    "def compute_metric(evalPred):\n",
    "    predictions, labels = evalPred\n",
    "    decode_preds = tokenzier.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenzier.pad_token_id)\n",
    "    decode_labels = tokenzier.batch_decode(labels, skip_special_tokens=True)\n",
    "    decode_preds = [\" \".join(p) for p in decode_preds]\n",
    "    decode_labels = [\" \".join(l) for l in decode_labels]\n",
    "    scores = rouge.get_scores(decode_preds, decode_labels, avg=True)\n",
    "    return {\n",
    "        \"rouge-1\": scores[\"rouge-1\"][\"f\"],\n",
    "        \"rouge-2\": scores[\"rouge-2\"][\"f\"],\n",
    "        \"rouge-l\": scores[\"rouge-l\"][\"f\"],\n",
    "    }\n",
    "args = Seq2SeqTrainingArguments(output_dir=\"./summary\", per_device_train_batch_size=4, per_device_eval_batch_size=8, gradient_accumulation_steps=8,\n",
    "    logging_steps=8, evaluation_strategy=\"epoch\", save_strategy=\"epoch\", metric_for_best_model=\"rouge-l\", predict_with_generate=True)\n",
    "trainer = Seq2SeqTrainer(args=args,  model=model,  train_dataset=tokenized_ds[\"train\"], eval_dataset=tokenized_ds[\"test\"], compute_metrics=compute_metric, tokenizer=tokenzier, data_collator=DataCollatorForSeq2Seq(tokenizer=tokenzier))\n",
    "trainer.train()\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(\"text2text-generation\", model=model, tokenizer=tokenzier, device=0)\n",
    "pipe(\"摘要生成:\\n\" + ds[\"test\"][-1][\"content\"], max_length=64, do_sample=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a69a0fb4b2c52fe4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 文本摘要\n",
    "# 基于GLM的文本摘要： AutoModelForSeq2SeqLM， Seq2SeqTrainer，Seq2SeqTrainingArguments\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "ds = Dataset.load_from_disk(\"./nlpcc_2017/\")\n",
    "ds = ds.train_test_split(100, seed=42)\n",
    "tokenzier = AutoTokenizer.from_pretrained(\"THUDM/glm-large-chinese\", trust_remote_code=True)\n",
    "def process_func(exmaples):\n",
    "    contents = [\"摘要生成: \\n\" + e + tokenzier.mask_token for e in exmaples[\"content\"]]\n",
    "    inputs = tokenzier(contents, max_length=384, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "    inputs = tokenzier.build_inputs_for_generation(inputs, targets=exmaples['title'], padding=True, max_gen_length=64)\n",
    "    return inputs\n",
    "tokenized_ds = ds.map(process_func, batched=True, remove_columns=ds[\"train\"].column_names)\n",
    "tokenzier.decode(tokenized_ds[\"train\"][0][\"input_ids\"])\n",
    "tokenized_ds[\"train\"][0][\"labels\"]\n",
    "print(tokenized_ds[\"train\"][0][\"position_ids\"])\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"THUDM/glm-large-chinese\", trust_remote_code=True)\n",
    "args = Seq2SeqTrainingArguments(output_dir=\"./summary_glm\", per_device_train_batch_size=4, per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=8, logging_steps=8, num_train_epochs=1)\n",
    "trainer = Seq2SeqTrainer(args=args, model=model, train_dataset=tokenized_ds[\"train\"], tokenizer=tokenzier,)  \n",
    "trainer.train()\n",
    "input_text = ds[\"test\"][-1][\"content\"]\n",
    "inputs = tokenzier(\"摘要生成: \\n\" + input_text + tokenzier.mask_token, return_tensors=\"pt\")\n",
    "inputs = tokenzier.build_inputs_for_generation(inputs, max_gen_length=64)\n",
    "inputs = inputs.to(\"cuda\")\n",
    "output = model.generate(**inputs, max_new_tokens=64, eos_token_id=tokenzier.eop_token_id, do_sample=True)\n",
    "tokenzier.decode(output[0].tolist())\n",
    "import torch\n",
    "model = model.eval()\n",
    "def predict_test():\n",
    "    predict = []\n",
    "    with torch.inference_mode():\n",
    "        for d in ds[\"test\"]:\n",
    "            inputs = tokenzier(\"摘要生成: \\n\" + d[\"content\"] + tokenzier.mask_token, return_tensors=\"pt\")\n",
    "            inputs = tokenzier.build_inputs_for_generation(inputs, max_gen_length=64)\n",
    "            inputs = inputs.to(\"cuda\")\n",
    "            output = model.generate(**inputs, max_new_tokens=64, eos_token_id=tokenzier.eop_token_id, do_sample=True)\n",
    "            predict.append(tokenzier.decode(output[0].tolist()).split(\"<|startofpiece|>\")[1].replace(\"<|endofpiece|>\", \"\").strip())\n",
    "            print(\"curID:\", len(predict))\n",
    "    return predict\n",
    "result = predict_test()\n",
    "from rouge_chinese import Rouge\n",
    "rouge = Rouge()\n",
    "docode_preds = [\" \".join(p) for p in result]\n",
    "decode_labels = [\" \".join(l) for l in ds[\"test\"][\"title\"]]\n",
    "scores = rouge.get_scores(docode_preds, decode_labels, avg=True)\n",
    "{\n",
    "    \"rouge-1\": scores[\"rouge-1\"][\"f\"],\n",
    "    \"rouge-2\": scores[\"rouge-2\"][\"f\"],\n",
    "    \"rouge-l\": scores[\"rouge-l\"][\"f\"],\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dd3c85e579a2638"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ad9836f57c6314c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
